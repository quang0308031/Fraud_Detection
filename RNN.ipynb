{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = np.zeros((2, 50*102), dtype=np.float32)\n",
    "h_prev = np.zeros((2, 512), dtype=np.float32)\n",
    "delta_t = np.ones((2, 50), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LessThanConstraint(tf.keras.constraints.Constraint):\n",
    "    def __init__(self, max_value):\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def __call__(self, w):\n",
    "        return tf.clip_by_value(w, clip_value_min=-float('inf'), clip_value_max=self.max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, d):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.d = d\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_aq = self.add_weight(name='Waq', shape=(self.hidden_dim * 2, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_ah = self.add_weight(name='Wah', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.ba = self.add_weight(name='ba', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.v = self.add_weight(name='v', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        #self._ati_dense = self.add_weight(name='ati', shape=(input_shape[-2], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, ht, ct, hi):\n",
    "        q = tf.concat((ht, ct), axis = -1)\n",
    "        aq = tf.matmul(q, self.W_aq)\n",
    "        ah = tf.matmul(hi, self.W_ah)\n",
    "\n",
    "        oti = tf.math.tanh(aq[:, tf.newaxis, ...] + ah + self.ba)\n",
    "\n",
    "        a = tf.matmul(oti, self.v)\n",
    "        ati = tf.exp(a)\n",
    "        ati = ati / tf.reduce_sum(ati, axis=1)[:, tf.newaxis, ...]\n",
    "\n",
    "        #ati = tf.matmul(ati, self._ati_dense)\n",
    "        e = tf.reduce_sum(ati * hi, axis=1)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        super(InteractionModule, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.wh = self.add_weight(name='wh', shape = (self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.we = self.add_weight(name='we', shape = (self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.wg = self.add_weight(name='wg', shape = (input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bh = self.add_weight(name='bh', shape = (1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, g, ht, e):\n",
    "        _h = tf.matmul(ht, self.wh)\n",
    "        _e = tf.matmul(e, self.we)\n",
    "        _g = tf.matmul(g, self.wg)\n",
    "        new_h = tf.math.tanh(_h + _e + _g + self.bh)\n",
    "        return new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cell(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, d, **kwargs):\n",
    "        super().__init__( **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attn = Attention(hidden_dim, d)\n",
    "        self.IM = InteractionModule(hidden_dim)\n",
    "        self.d = d\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_sh = self.add_weight(name='Wsh', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_sx = self.add_weight(name='Wsx', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_st = self.add_weight(name='Wst', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bs = self.add_weight(name='bs', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_fh = self.add_weight(name='Wfh', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_fx = self.add_weight(name='Wfx', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_fs = self.add_weight(name='Wfs', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True, constraint=LessThanConstraint(max_value=0.0))\n",
    "        self.bf = self.add_weight(name='bf', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_ih = self.add_weight(name='Wih', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_ix = self.add_weight(name='Wix', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_is = self.add_weight(name='Wis', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bi = self.add_weight(name='bi', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_Th = self.add_weight(name='WTh', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_Tx = self.add_weight(name='WTx', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_Ts = self.add_weight(name='WTs', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bT = self.add_weight(name='bT', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_Eh = self.add_weight(name='WEh', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_Ex = self.add_weight(name='WEx', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_Es = self.add_weight(name='WEs', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bE = self.add_weight(name='bE', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_oh = self.add_weight(name='Woh', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_ox = self.add_weight(name='Wox', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_os = self.add_weight(name='Wos', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bo = self.add_weight(name='bo', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        return super().build(input_shape)\n",
    "    \n",
    "    def call(self, input, h_prev, c_prev, delta_t, mem):\n",
    "        sh = tf.matmul(h_prev, self.W_sh)\n",
    "        sx = tf.matmul(input, self.W_sx)\n",
    "        st = tf.matmul(delta_t, self.W_st)\n",
    "\n",
    "        s = tf.tanh(sh + sx + st + self.bs)\n",
    "\n",
    "        fh = tf.matmul(h_prev, self.W_fh)\n",
    "        fx = tf.matmul(input, self.W_fx)\n",
    "        fs = tf.matmul(s, self.W_fs)\n",
    "\n",
    "        f = tf.sigmoid(fh + fx  + fs + self.bf)\n",
    "\n",
    "        ih = tf.matmul(h_prev, self.W_ih)\n",
    "        ix = tf.matmul(input, self.W_ix)\n",
    "        i_s = tf.matmul(s, self.W_is)\n",
    "\n",
    "        i = tf.sigmoid(ih + ix  + i_s + self.bi)\n",
    "\n",
    "        Th = tf.matmul(h_prev, self.W_Th)\n",
    "        Tx = tf.matmul(input, self.W_Tx)\n",
    "        Ts = tf.matmul(s, self.W_Ts)\n",
    "\n",
    "        T = tf.sigmoid(Th + Tx  + Ts + self.bT)\n",
    "\n",
    "        Eh = tf.matmul(h_prev, self.W_Eh)\n",
    "        Ex = tf.matmul(input, self.W_Ex)\n",
    "        Es = tf.matmul(s, self.W_Es)\n",
    "\n",
    "        E = tf.tanh(Eh + Ex  + Es + self.bE)\n",
    "\n",
    "        new_c = f * c_prev + i * E + T * s\n",
    "\n",
    "        oh = tf.matmul(h_prev, self.W_oh)\n",
    "        ox = tf.matmul(input, self.W_ox)\n",
    "        os = tf.matmul(s, self.W_os)\n",
    "\n",
    "        o = tf.sigmoid(oh + ox  + os + self.bo)\n",
    "\n",
    "        _h = o * tf.math.tanh(new_c)\n",
    "\n",
    "        e = self.attn(_h, new_c, mem)\n",
    "        new_h = self.IM(input, _h, e)\n",
    "        return new_h, new_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable()\n",
    "class TH_LSTM(tf.keras.Model):\n",
    "    def __init__(self, hidden_dim, output_dim, d,*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.d = d\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.hc_init = self.add_weight(name='h_init', shape = (1, self.hidden_dim), initializer='zeros')\n",
    "        self.cell = cell(self.hidden_dim, self.d)\n",
    "        self.output_dense = self.add_weight(name='op', shape = (self.hidden_dim, self.output_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self._init = self.add_weight(name='init', shape = (input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        return super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        str_mem = tf.ones_like(inputs)\n",
    "        str_mem = tf.matmul(str_mem, self._init)[:,:-1]\n",
    "        \n",
    "        h = c = self.hc_init\n",
    "        for i in range(inputs.shape[1]):\n",
    "            h, c = self.cell(inputs[:,i,..., 1:], h, c, inputs[:, i,... ,0:1], str_mem)\n",
    "            str_mem = tf.concat((str_mem, h[:, tf.newaxis, ...]), axis = 1)[:,:self.d,...]\n",
    "        output = tf.matmul(h, self.output_dense)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, lambda1, lambda2):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.channel = 0\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) == 3:\n",
    "            self.channel = 1\n",
    "        else:\n",
    "            self.channel = input_shape[-1]\n",
    "        self.W_t = self.add_weight(name='Wt', shape=(self.channel, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_s = self.add_weight(name='Ws', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        #self._ati_dense = self.add_weight(name='ati', shape=(input_shape[-2], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if tf.rank(inputs) == 3:\n",
    "            inputs = inputs[..., tf.newaxis]\n",
    "        gt = tf.matmul(inputs, self.W_t)\n",
    "        gt = self.relu(gt)\n",
    "        a1 = tf.math.exp(gt * (1 - self.lambda1))\n",
    "        a1 = a1 / tf.reduce_sum(a1, axis = 1)[:, tf.newaxis]\n",
    "        rept = tf.tile(tf.reduce_sum(a1 * inputs, axis=1, keepdims=True), [1, inputs.shape[1], 1, 1])\n",
    "\n",
    "        gs = tf.matmul(rept, self.W_s)\n",
    "        gs = self.relu(gs)\n",
    "        a2 = tf.math.exp(gs * (1 - self.lambda2))\n",
    "        a2 = a2 / tf.reduce_sum(a2, axis = 2)[:, :, tf.newaxis]\n",
    "        H = a2 * inputs\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STA_NN(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, lambda1, lambda2, num_c):\n",
    "        super(STA_NN, self).__init__()\n",
    "        self.attn = Attention(hidden_dim, lambda1, lambda2)\n",
    "        self.conv2d = tf.keras.Sequential(\n",
    "            [\n",
    "            tf.keras.layers.Conv2D(filters = hidden_dim, kernel_size=3, padding='same')\n",
    "            for i in range(num_c)\n",
    "            ])\n",
    "        self.top = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(256, activation='relu'),\n",
    "                tf.keras.layers.Dense(32, activation='relu'),\n",
    "                tf.keras.layers.Dense(2, activation='softmax')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = self.attn(inputs)\n",
    "\n",
    "        output = self.conv2d(output)\n",
    "\n",
    "        output = self.top(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.48859218, 0.5114078 ],\n",
       "       [0.49352467, 0.5064753 ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STA_NN(512, 0.8, 0.8, 10)(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mpoint, y\u001b[38;5;241m=\u001b[39mpoint[:,\u001b[38;5;241m0\u001b[39m,:], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "t.fit(x=point, y=point[:,0,:], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'cell_1/WEs:0' shape=(512, 512) dtype=float32, numpy=\n",
       "array([[-0.04626746,  0.00359627, -0.01755141, ..., -0.02747763,\n",
       "        -0.03189887, -0.03276787],\n",
       "       [-0.01951   , -0.01298589, -0.01607934, ..., -0.01270718,\n",
       "         0.05056564, -0.01247779],\n",
       "       [-0.03104064, -0.00652095,  0.01753465, ..., -0.02565206,\n",
       "         0.01810547, -0.03895471],\n",
       "       ...,\n",
       "       [ 0.03841003,  0.00052832, -0.04342259, ...,  0.03012684,\n",
       "         0.03617146, -0.0062141 ],\n",
       "       [-0.02431568,  0.0073331 ,  0.04505984, ...,  0.00349364,\n",
       "        -0.00231323,  0.02137714],\n",
       "       [ 0.04862043, -0.04206186,  0.02347884, ...,  0.04003372,\n",
       "         0.03943432,  0.00278409]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cell.W_Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 217ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.31168705,  0.12628564, -0.39654619, -0.05241583,  0.30171004,\n",
       "        -0.40108848, -0.1860197 ,  0.21693905, -0.24783114, -0.29487348,\n",
       "         0.22307952,  0.37625092,  0.2241749 ,  0.3506708 ,  0.45104262,\n",
       "        -0.56199753,  0.36240155, -0.09314545, -0.2025147 , -0.01523836,\n",
       "         0.40751982,  0.35551974,  0.26489767,  0.05543795, -0.1606291 ,\n",
       "        -0.20981666,  0.1846074 ,  0.4004755 , -0.11343882,  0.18619972,\n",
       "        -0.22497378,  0.46918055, -0.28560185,  0.54379714,  0.27628478,\n",
       "         0.27203625, -0.3975439 , -0.18416168, -0.16144982,  0.05874888,\n",
       "        -0.28259882,  0.32966453, -0.34079683, -0.3700378 , -0.04298227,\n",
       "        -0.02882063,  0.1003615 ,  0.4482764 , -0.03793479,  0.26154327,\n",
       "        -0.03383964,  0.25987655,  0.14384776,  0.2574718 , -0.00138964,\n",
       "         0.10461923, -0.09818178,  0.17011946, -0.49011055,  0.39715326,\n",
       "         0.49603778, -0.23160155, -0.40634608, -0.26753786, -0.02015402,\n",
       "        -0.04023924,  0.28586146, -0.28651053, -0.3869711 , -0.217109  ,\n",
       "         0.15002126,  0.42024797,  0.43623653,  0.36348563, -0.08815306,\n",
       "        -0.29235563,  0.16956086,  0.02965944, -0.19853063, -0.08782773,\n",
       "         0.22639601,  0.10241229,  0.15396853,  0.22192357, -0.21969709,\n",
       "         0.53911245, -0.14601101,  0.12068152, -0.31813824, -0.27663037,\n",
       "         0.0448024 , -0.11669853,  0.4180572 , -0.0149916 , -0.13687715,\n",
       "         0.38650897,  0.3458753 , -0.21032965, -0.25701123,  0.20114924,\n",
       "        -0.2268538 , -0.17368978]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(point[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "# Ma trận đầu vào\n",
    "input_matrix = tf.random.uniform(shape=(10, 50, 512))\n",
    "\n",
    "# Chuyển đổi ma trận bằng lớp Dense\n",
    "output_matrix = dense_layer(input_matrix)\n",
    "\n",
    "# Kích thước của ma trận đầu ra\n",
    "print(output_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A_LSTM(tf.keras.Model):\n",
    "    def __init__(self,num_classes,units, merge_units, dropout, head, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.head = head\n",
    "        self.LSTM_blocks = [\n",
    "            tf.keras.Sequential(\n",
    "                [\n",
    "                    tf.keras.layers.LSTM(units=units, return_sequences=True),\n",
    "                    tf.keras.layers.Dropout(dropout),\n",
    "                    tf.keras.layers.LSTM(units=units*2),\n",
    "                    tf.keras.layers.Dropout(dropout),\n",
    "                    tf.keras.layers.Dense(merge_units, activation='relu')\n",
    "                ]\n",
    "            )\n",
    "        for i in range(head)]\n",
    "        self.forward = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(merge_units, activation='relu'),\n",
    "                tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        _dense_output = []\n",
    "        for i in range(self.head):\n",
    "            otp = self.LSTM_blocks[i](inputs[i])\n",
    "            _dense_output.append(otp)\n",
    "        _dense_output = tf.concat(_dense_output, axis=-1)\n",
    "        output = self.forward(_dense_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "point = np.zeros((2, 50, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.5, 0.5],\n",
       "       [0.5, 0.5]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_LSTM(2, 128, 64, 0.5, 3)([point, point, point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acbe,aecd->abcd'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn._combine_equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aecd,abcd->acbe'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn._dot_product_equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = attn._query_dense(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50, 8, 512), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = attn._key_dense(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = attn._value_dense(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.einsum(attn._dot_product_equation, key, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 8, 50, 50), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50, 8, 512), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.einsum(attn._combine_equation, t, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, d):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.d = d\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_as = self.add_weight(name='Was', shape=(self.hidden_dim * 2, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_ah = self.add_weight(name='Wah', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.ba = self.add_weight(name='ba', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.v = self.add_weight(name='v', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        #self._ati_dense = self.add_weight(name='ati', shape=(input_shape[-2], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, o, ct, hi):\n",
    "        ht = o * tf.tanh(ct)\n",
    "        q = tf.concat((ht, ct), axis = -1)\n",
    "        as = tf.matmul(q, self.W_as)\n",
    "        ah = tf.matmul(hi, self.W_ah)\n",
    "\n",
    "        oti = tf.math.tanh(as[:, tf.newaxis, ...] + ah + self.ba)\n",
    "        dims=tf.range(len(tf.shape(oti)))\n",
    "        perm = tf.concat((dims[:-2], dims[-1:], dims[-2:-1]), axis = 0)\n",
    "        oti = tf.transpose(oti, perm=perm)\n",
    "\n",
    "        a = tf.matmul(self.v, oti)[:,0]\n",
    "        ati = tf.exp(a)\n",
    "        ati = ati / tf.reduce_sum(ati, axis=1)[:, tf.newaxis, ...]\n",
    "\n",
    "        #ati = tf.matmul(ati, self._ati_dense)\n",
    "        e = tf.reduce_sum(ati[..., tf.newaxis] * hi, axis=1)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cell(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, d, **kwargs):\n",
    "        super().__init__( **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attn = Attention(hidden_dim, d)\n",
    "        self.IM = InteractionModule(hidden_dim)\n",
    "        self.d = d\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_fh = self.add_weight(name='Wfh', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_fx = self.add_weight(name='Wfx', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_ft = self.add_weight(name='Wft', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bf = self.add_weight(name='bf', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_ih = self.add_weight(name='Wih', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_ix = self.add_weight(name='Wix', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bi = self.add_weight(name='bi', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_oh = self.add_weight(name='Woh', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_ox = self.add_weight(name='Wox', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bo = self.add_weight(name='bo', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "\n",
    "        self.W_ch = self.add_weight(name='Wch', shape=(self.hidden_dim, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.W_cx = self.add_weight(name='Wcx', shape=(input_shape[-1], self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        self.bc = self.add_weight(name='bo', shape=(1, self.hidden_dim), initializer=\"random_uniform\", trainable=True)\n",
    "        return super().build(input_shape)\n",
    "    \n",
    "    def call(self, input, h_prev, c_prev, delta_t, mem):\n",
    "        fh = tf.matmul(h_prev, self.W_fh)\n",
    "        fx = tf.matmul(input, self.W_fx)\n",
    "        ft = tf.matmul(delta_t, self.W_ft)\n",
    "\n",
    "        f = tf.sigmoid(fh + fx  + ft + self.bf)\n",
    "\n",
    "        ih = tf.matmul(h_prev, self.W_ih)\n",
    "        ix = tf.matmul(input, self.W_ix)\n",
    "\n",
    "        i = tf.sigmoid(ih + ix + self.bi)\n",
    "\n",
    "        oh = tf.matmul(h_prev, self.W_oh)\n",
    "        ox = tf.matmul(input, self.W_ox)\n",
    "\n",
    "        o = tf.sigmoid(oh + ox + self.bo)\n",
    "\n",
    "        _ch = tf.matmul(self.W_ch, h_prev)\n",
    "        _cx = tf.matmul(self.W_cx, input)\n",
    "        _c = tf.tanh(_ch + _cx + self.bc)\n",
    "\n",
    "        new_c = f * c_prev + i * _c\n",
    "\n",
    "        e = self.attn(o, new_c, mem)\n",
    "        new_h = self.IM(input, _h, e)\n",
    "        return new_h, new_c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
